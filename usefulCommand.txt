hadoop fs -text output/*.txt
hadoop com.sun.tools.javac.Main *.java
jar cf language2.jar *.class
hadoop jar language2.jar Driver output/language output/language2 7 5
hdfs dfs -cat output/language2/part-r-00000
hdfs dfs -mkdir output/language
hdfs dfs -ls output
hdfs dfs -put ./*.txt input/language
hdfs dfs -rm output/wordcount/*
hdfs dfs -rmr output
hadoop fs -rmdir output
docker cp LanguageModel.java 2381e15c2e20:/root/src/language_stage2/LanguageModel.java

start docker: http://kiwenlau.com/2016/06/12/160612-hadoop-cluster-docker-update/

第一次往hdfs里加文件夹，要加-p
hdfs dfs -mkdir -p input
加了第一个之后，后面的不用加-p也可以添加

logs:
root@hadoop-master:~/data/pageRank# hdfs dfs -mkdir input
mkdir: `input': No such file or directory
root@hadoop-master:~/data/pageRank# hdfs dfs -mkdir -p input
root@hadoop-master:~/data/pageRank# hdfs dfs -mkdir output
root@hadoop-master:~/data/pageRank# hdfs dfs -ls 
Found 2 items
drwxr-xr-x   - root supergroup          0 2017-03-10 03:48 input
drwxr-xr-x   - root supergroup          0 2017-03-10 03:50 output



如果hadoop com.sun.tools.javac.Main WordCounter.java有问题
export HADOOP_CLASSPATH=$JAVA_HOME/lib/tools.jar

logs:
root@hadoop-master:~/src# hadoop com.sun.tools.javac.Main WordCounter.java
Error: Could not find or load main class com.sun.tools.javac.Main
root@hadoop-master:~/src# JAVA_HOME
bash: JAVA_HOME: command not found
root@hadoop-master:~/src# $JAVA_HOME
bash: /usr/lib/jvm/java-7-openjdk-amd64: Is a directory
root@hadoop-master:~/src# javac -version
javac 1.7.0_101
root@hadoop-master:~/src# export HADOOP_CLASSPATH=$JAVA_HOME/lib/tools.jar
root@hadoop-master:~/src# hadoop com.sun.tools.javac.Main WordCounter.java
javac: file not found: WordCounter.java
Usage: javac <options> <source files>
use -help for a list of possible options
root@hadoop-master:~/src# hadoop com.sun.tools.javac.Main *.java
Note: WordCount.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
root@hadoop-master:~/src# jar cf wordCount.jar *.class

mkdir data
mkdir src
cd src
mkdir pageRank
cd ..
mkdir pageRank
cd pageRank
hdfs dfs -mkdir -p input
hdfs dfs -mkdir output
hdfs dfs -mkdir input/pageRank
# add data
# go to data file
hdfs dfs -put *.txt input/pageRank

# stop
# add src code 
# go to src file
cd ..
cd ..
cd data
cd pageRank
export HADOOP_CLASSPATH=$JAVA_HOME/lib/tools.jar
hadoop com.sun.tools.javac.Main *.java
jar cf pageRank.jar *.class
hadoop jar pageRank.jar pageRank input/pageRank/transitionsmall.txt input/pageRank/prsmall.txt output/pageRank
hdfs dfs -cat output/pageRank/part-r-00000

docker cp pageRank.java 812f058f6a35:/root/src/pageRank/pageRank.java
docker cp transitionsmall.txt 812f058f6a35:/root/data/pageRank/transitionsmall.txt
docker cp prsmall.txt 812f058f6a35:/root/data/pageRank/prsmall.txt

重启docker:
步骤1：
ZHANGdeMacBook-Pro:data zhangchi$ docker ps -a
CONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS                        PORTS               NAMES
635cceb68e7b        kiwenlau/hadoop:1.0   "sh -c 'service ss..."   24 minutes ago      Exited (137) 39 seconds ago                       hadoop-slave2
04826f3af272        kiwenlau/hadoop:1.0   "sh -c 'service ss..."   24 minutes ago      Exited (137) 39 seconds ago                       hadoop-slave1
812f058f6a35        kiwenlau/hadoop:1.0   "sh -c 'service ss..."   24 minutes ago      Exited (137) 39 seconds ago                       hadoop-master
ZHANGdeMacBook-Pro:data zhangchi$ docker start 812f058f6a35
812f058f6a35
ZHANGdeMacBook-Pro:data zhangchi$ docker start 04826f3af272
04826f3af272
ZHANGdeMacBook-Pro:data zhangchi$ docker start 635cceb68e7b
635cceb68e7b
步骤2：
./start-container.sh (注意mv的句子已经被注释掉)
步骤3：
./start-hadoop.sh
就可以了
